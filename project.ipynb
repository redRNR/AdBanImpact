{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce9bddee-d174-4d84-bbe7-47a5919277ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AFTER', 'AFTERXCharges_Price', 'AFTERXTop_Demanded', 'AFTERXTop_Rated',\n",
      "       'AFTERXUndiversified', 'AFTERXYoung', 'Ad_Networks', 'Ad_Views', 'Age',\n",
      "       'Bug_Fix', 'Charges_Price', 'Collects_User_ID', 'Demand',\n",
      "       'Feature_Update', 'Feature_Update_lag', 'Feature_Updates', 'File_Size',\n",
      "       'Firm_Size', 'Log_Demand', 'Log_Firm_Size', 'Log_Price', 'One_Employee',\n",
      "       'Permissions', 'Price', 'Rating', 'TREATXAFTER',\n",
      "       'TREATXAFTERXCharges_Price', 'TREATXAFTERXTop_Demanded',\n",
      "       'TREATXAFTERXTop_Rated', 'TREATXAFTERXUndiversified',\n",
      "       'TREATXAFTERXYoung', 'Top_Demanded', 'Top_Rated', 'Undiversified',\n",
      "       'Update', 'Young', 'ad_networks_above_median', 'ads_above_median',\n",
      "       'ann_TREAT', 'app_num', 'collected_id', 'genre_cons', 'genre_num',\n",
      "       'ym'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the .dta file\n",
    "filepath = r'C:\\Users\\azraj\\OneDrive\\Desktop\\MA Economics\\Fall Term\\Causal ML\\Project\\Targetted Ads\\replication_package_MS-INS-21-00828\\at.dta'  # Update this path to the location of your .dta file\n",
    "\n",
    "# Load the .dta file\n",
    "panel_data = pd.read_stata(filepath)\n",
    "print(panel_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1664fefe-e867-4b56-8df8-99d3670b0030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running model for Rating\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Rating:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: 0.0176**\n",
      "Standard Error: (0.0078)\n",
      "Age: -0.0000\n",
      "Standard Error: (0.0001)\n",
      "Price: -0.0257\n",
      "Standard Error: (0.0292)\n",
      "Log_Firm_Size: -0.0050\n",
      "Standard Error: (0.0072)\n",
      "One_Employee: -0.0365*\n",
      "Standard Error: (0.0214)\n",
      "Feature_Update: 0.0123**\n",
      "Standard Error: (0.0048)\n",
      "Log_Demand: -0.0769***\n",
      "Standard Error: (0.0078)\n",
      "\n",
      "Observations: 88,566\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0246\n",
      "\n",
      "============================================================\n",
      "Running model for Log_Demand\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Log_Demand:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: -0.0256\n",
      "Standard Error: (0.0178)\n",
      "Age: -0.0003*\n",
      "Standard Error: (0.0002)\n",
      "Price: -1.1874**\n",
      "Standard Error: (0.4895)\n",
      "Log_Firm_Size: 0.1755***\n",
      "Standard Error: (0.0220)\n",
      "One_Employee: 0.0047\n",
      "Standard Error: (0.0589)\n",
      "Feature_Update: -0.0786***\n",
      "Standard Error: (0.0249)\n",
      "\n",
      "Observations: 93,881\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0110\n",
      "\n",
      "============================================================\n",
      "Running model for File_Size\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for File_Size:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: -0.0822\n",
      "Standard Error: (0.1780)\n",
      "Age: -0.0024\n",
      "Standard Error: (0.0016)\n",
      "Price: -5.5422\n",
      "Standard Error: (4.4768)\n",
      "Log_Firm_Size: -0.1575\n",
      "Standard Error: (0.2130)\n",
      "One_Employee: -1.0756\n",
      "Standard Error: (0.9424)\n",
      "Feature_Update: 1.2139***\n",
      "Standard Error: (0.3387)\n",
      "Log_Demand: 0.3238**\n",
      "Standard Error: (0.1362)\n",
      "\n",
      "Observations: 73,067\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0031\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(panel_data):\n",
    "    \"\"\"Prepare data for regression analysis\"\"\"\n",
    "    df = panel_data.copy()\n",
    "    \n",
    "    # Convert to panel format\n",
    "    df = df.set_index(['app_num', 'ym'])\n",
    "    \n",
    "    # Ensure datatypes\n",
    "    numeric_cols = ['Feature_Update', 'TREATXAFTER', 'Log_Demand', 'Age', \n",
    "                    'Price', 'Log_Firm_Size', 'One_Employee', 'Feature_Update_lag',\n",
    "                    'Rating', 'File_Size']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    df['genre_num'] = df['genre_num'].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_model(data, dependent_var, controls=True):\n",
    "    \"\"\"Run the DiD model for the specified dependent variable\"\"\"\n",
    "    exog_vars = ['TREATXAFTER']\n",
    "    \n",
    "    # Add controls\n",
    "    if controls:\n",
    "        additional_vars = ['Age', 'Price', 'Log_Firm_Size', 'One_Employee', 'Feature]\n",
    "        if dependent_var != 'Log_Demand':\n",
    "            additional_vars.append('Log_Demand')\n",
    "        exog_vars.extend(additional_vars)\n",
    "    \n",
    "    # Drop rows with NaN in the dependent variable\n",
    "    data = data.dropna(subset=[dependent_var])\n",
    "    \n",
    "    # Create the model\n",
    "    model = PanelOLS(\n",
    "        dependent=data[dependent_var],\n",
    "        exog=data[exog_vars],\n",
    "        entity_effects=True,\n",
    "        time_effects=True,\n",
    "        check_rank=False\n",
    "    )\n",
    "    \n",
    "    # Fit with clustered standard errors\n",
    "    results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_formatted_results(results, dependent_var):\n",
    "    \"\"\"Print formatted results\"\"\"\n",
    "    print(f\"\\nResults for {dependent_var}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Print coefficients and standard errors for all variables\n",
    "    for var in results.params.index:\n",
    "        coef = results.params[var]\n",
    "        se = results.std_errors[var]\n",
    "        stars = ''\n",
    "        pval = results.pvalues[var]\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        print(f\"{var}: {coef:.4f}{stars}\")\n",
    "        print(f\"Standard Error: ({se:.4f})\")\n",
    "    \n",
    "    print(f\"\\nObservations: {results.nobs:,}\")\n",
    "    print(f\"Game fixed effects: x\")\n",
    "    print(f\"Month fixed effects: x\")\n",
    "    print(f\"R-squared: {results.rsquared:.4f}\")\n",
    "\n",
    "def run_new_models(data):\n",
    "    \"\"\"Run models for Rating, Log_Demand, and File_Size\"\"\"\n",
    "    dependent_vars = ['Rating', 'Log_Demand', 'File_Size']\n",
    "    results = {}\n",
    "    \n",
    "    for dv in dependent_vars:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running model for {dv}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model_results = run_model(data, dv)\n",
    "        print_formatted_results(model_results, dv)\n",
    "        results[dv] = model_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Load the data\n",
    "    filepath = r'C:\\Users\\azraj\\OneDrive\\Desktop\\MA Economics\\Fall Term\\Causal ML\\Project\\Targetted Ads\\replication_package_MS-INS-21-00828\\at.dta'\n",
    "    panel_data = pd.read_stata(filepath)\n",
    "    \n",
    "    # Prepare the data\n",
    "    panel_data = prepare_data(panel_data)\n",
    "    \n",
    "    # Run new models\n",
    "    new_results = run_new_models(panel_data)\n",
    "    \n",
    "    return new_results, panel_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, panel_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5f96ea2-7d34-4df7-997f-1dc67141ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Rating:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: 0.0221***\n",
      "Standard Error: (0.0083)\n",
      "\n",
      "Observations: 93,428\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Rating:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: 0.0175**\n",
      "Standard Error: (0.0078)\n",
      "Log_Demand: -0.0771***\n",
      "Standard Error: (0.0078)\n",
      "Feature_Update: 0.0124***\n",
      "Standard Error: (0.0048)\n",
      "\n",
      "Observations: 88,566\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0244\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(panel_data):\n",
    "    \"\"\"Prepare data for regression analysis\"\"\"\n",
    "    df = panel_data.copy()\n",
    "    \n",
    "    # Convert to panel format\n",
    "    df = df.set_index(['app_num', 'ym'])\n",
    "    \n",
    "    # Ensure datatypes\n",
    "    numeric_cols = ['Rating', 'TREATXAFTER', 'Log_Demand', 'Age', 'Price', 'Log_Firm_Size', 'One_Employee']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    df['genre_num'] = df['genre_num'].astype('category')\n",
    "    \n",
    "    # Drop rows with NaN in the dependent variable (Rating)\n",
    "    df = df.dropna(subset=['Rating'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_ratings_model(data, additional_vars=None):\n",
    "    \"\"\"Run the DiD model for the Ratings dependent variable\"\"\"\n",
    "    exog_vars = ['TREATXAFTER']\n",
    "    \n",
    "    # Add controls\n",
    "    if additional_vars:\n",
    "        exog_vars.extend(additional_vars)\n",
    "    \n",
    "    # Create the model\n",
    "    model = PanelOLS(\n",
    "        dependent=data['Rating'],\n",
    "        exog=data[exog_vars],\n",
    "        entity_effects=True,\n",
    "        time_effects=True,\n",
    "        check_rank=False\n",
    "    )\n",
    "    \n",
    "    # Fit with clustered standard errors\n",
    "    results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_formatted_results(results):\n",
    "    \"\"\"Print formatted results for the Ratings model\"\"\"\n",
    "    print(\"\\nResults for Rating:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Print coefficients and standard errors for all variables\n",
    "    for var in results.params.index:\n",
    "        coef = results.params[var]\n",
    "        se = results.std_errors[var]\n",
    "        stars = ''\n",
    "        pval = results.pvalues[var]\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        print(f\"{var}: {coef:.4f}{stars}\")\n",
    "        print(f\"Standard Error: ({se:.4f})\")\n",
    "    \n",
    "    print(f\"\\nObservations: {results.nobs:,}\")\n",
    "    print(\"Game fixed effects: x\")\n",
    "    print(\"Month fixed effects: x\")\n",
    "    print(f\"R-squared: {results.rsquared:.4f}\")\n",
    "\n",
    "def main():\n",
    "    # Load the data\n",
    "    filepath = r'C:\\Users\\azraj\\OneDrive\\Desktop\\MA Economics\\Fall Term\\Causal ML\\Project\\Targetted Ads\\replication_package_MS-INS-21-00828\\at.dta'\n",
    "    panel_data = pd.read_stata(filepath)\n",
    "    \n",
    "    # Prepare the data\n",
    "    panel_data = prepare_data(panel_data)\n",
    "    \n",
    "    # Run the Ratings model\n",
    "    base_model_results = run_ratings_model(panel_data)\n",
    "    print_formatted_results(base_model_results)\n",
    "    \n",
    "    # Run the Ratings model with additional variables\n",
    "    additional_vars = ['Log_Demand', 'Feature_Update']\n",
    "    extended_model_results = run_ratings_model(panel_data, additional_vars)\n",
    "    print_formatted_results(extended_model_results)\n",
    "    \n",
    "    return base_model_results, extended_model_results, panel_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_results, extended_results, panel_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af6467-47ab-4307-bf77-7dc1a95c5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "sqft_tree = tree.DecisionTreeRegressor(max_depth=3).fit(X,Y)\n",
    "# use the fitted tree to predict\n",
    "y_pred_tree = sqft_tree.predict(X)\n",
    "\n",
    "# find the error of prediction (MSE)\n",
    "from sklearn import metrics\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y, y_pred_tree))\n",
    "sqrf_fig = plt.figure(figsize=(25,20))\n",
    "sqrf_fig = tree.plot_tree(sqft_tree, feature_names=X.columns, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067af6e-be84-4d90-a5a5-d9e6c9df535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "clf = DTC(criterion='entropy',\n",
    "          max_depth=3,\n",
    "          random_state=0)        \n",
    "clf.fit(X, y)\n",
    "\n",
    "ax = subplots(figsize=(12,12))[1]\n",
    "feature_names = X.columns\n",
    "plot_tree(clf,\n",
    "          feature_names=feature_names,\n",
    "          ax=ax);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674ff89-de46-4a80-b3ca-2f74152aaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest: using 5 features\n",
    "\n",
    "# define and fit\n",
    "regr_clf = RandomForestClassifier(max_features=5, random_state=1).fit(X, y)\n",
    "\n",
    "#predict\n",
    "pred = regr_clf.predict(X)\n",
    "\n",
    "#calculate MSE\n",
    "rf_mse = mean_squared_error(y, pred)\n",
    "Importance = pd.DataFrame({'Importance':regr_clf.feature_importances_*100}, index=X.columns)\n",
    "Importance.sort_values('Importance', axis=0, ascending=True).plot(kind='barh', color='r', )\n",
    "plt.title('Importance Score Plot')\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.gca().legend_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fa0a8-6312-4073-b3a4-bcca606f17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Convert the data into XGBoost's DMatrix format\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "# Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the XGBoost model with the optimal number of boosting rounds\n",
    "model = xgb.train(params, dtrain, num_boost_round= 10)\n",
    "\n",
    "# Make predictions \n",
    "y_pred = model.predict(dtrain)\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y, y_pred, c='grey', alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('True Y')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.title('Y vs Predicted Y (Y hat)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cca8a2-173b-46ae-8e3b-de21ceaadda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize LassoCV with cross-validation and a custom range of alphas\n",
    "custom_alphas = np.logspace(-5, 1, 100)  # Custom range of alphas\n",
    "lassoCV = LassoCV(\n",
    "    alphas=custom_alphas,  # Use the custom alphas\n",
    "    cv=kfold,\n",
    "    max_iter=100000,\n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a pipeline with scaler and LassoCV\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lassoCV)])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeCV.fit(X, Y)\n",
    "print(\"\\nLassoCV model fitted successfully.\")\n",
    "\n",
    "# Retrieve the tuned alpha (regularization parameter)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "best_alpha = tuned_lasso.alpha_\n",
    "print(f\"\\nOptimal alpha determined by cross-validation: {best_alpha}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plotting Cross-validated MSE with Error Bars\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Extract the cross-validated MSEs and standard deviations\n",
    "mse_path_mean = np.mean(tuned_lasso.mse_path_, axis=1)\n",
    "mse_path_std = np.std(tuned_lasso.mse_path_, axis=1)\n",
    "\n",
    "# Plotting the cross-validated MSE vs. -log(lambda) with error bars\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(-np.log10(tuned_lasso.alphas_), mse_path_mean, yerr=mse_path_std / np.sqrt(5), fmt='o-')\n",
    "plt.axvline(-np.log10(best_alpha), color='k', linestyle='--')\n",
    "plt.xlabel('$-\\\\log(\\\\lambda)$', fontsize=20)\n",
    "plt.ylabel('Cross-validated MSE', fontsize=20)\n",
    "plt.title('Lasso Regression Cross-Validated MSE', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plotting Lasso Coefficients Path\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Compute the Lasso path (coefficients for different alphas)\n",
    "X_scaled = scaler.transform(X)  # Lasso expects standardized data\n",
    "\n",
    "# Define a range of alpha values (logarithmically spaced)\n",
    "num_alphas = 100\n",
    "alphas_lasso = np.logspace(-5, 1, num_alphas)\n",
    "\n",
    "# Compute the Lasso path\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X_scaled, Y, alphas=alphas_lasso)\n",
    "\n",
    "# Create a DataFrame for the solution path\n",
    "feature_names = X.columns\n",
    "soln_path = pd.DataFrame(coefs_lasso.T, columns=feature_names, index=-np.log10(alphas_lasso))\n",
    "\n",
    "# Plot the Lasso coefficient path\n",
    "plt.figure(figsize=(10, 6))\n",
    "for feature in feature_names:\n",
    "    plt.plot(soln_path.index, soln_path[feature], label=feature)\n",
    "\n",
    "plt.xlabel('$-\\\\log(\\\\lambda)$', fontsize=14)\n",
    "plt.ylabel('Standardized Coefficients', fontsize=14)\n",
    "plt.title('Lasso Regression Plot', fontsize=16)\n",
    "plt.legend(title='Features')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b6841-8f9a-476b-ad16-6b0cb87025f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of lambda values (regularization strengths)\n",
    "lambda_min_exponent = -5\n",
    "lambda_max_exponent = 8\n",
    "num_lambdas = 100\n",
    "lambdas = 10 ** np.linspace(lambda_max_exponent, lambda_min_exponent, num_lambdas)\n",
    "\n",
    "# Fit Elastic Net model paths with l1_ratio=0 (Ridge Regression)\n",
    "alphas, coefs, _ = enet_path(X_scaled, Y, l1_ratio=0.0, alphas=lambdas)\n",
    "\n",
    "# Create a DataFrame for the solution path\n",
    "coef_df = pd.DataFrame(coefs, index=['TREATXAFTER', 'Age', 'Log_Firm_Size', 'Price', 'One_Employee'], columns=-np.log(alphas))\n",
    "\n",
    "# Plot the solution path\n",
    "plt.figure(figsize=(10, 6))\n",
    "for feature in coef_df.index:\n",
    "    plt.plot(coef_df.columns, coef_df.loc[feature], label=feature)\n",
    "\n",
    "plt.xlabel('$-\\log(\\lambda)$', fontsize=14)\n",
    "plt.ylabel('Standardized Coefficients', fontsize=14)\n",
    "plt.title('Ridge Regression Plot', fontsize=16)\n",
    "plt.legend(title='Features')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e910a-8dbe-4298-b2de-71cfc07e35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of lambda values (regularization strengths)\n",
    "lambda_min_exponent = -8\n",
    "lambda_max_exponent = 8\n",
    "num_lambdas = 100\n",
    "lambdas = 10 ** np.linspace(lambda_max_exponent, lambda_min_exponent, num_lambdas)\n",
    "\n",
    "# Set up the pipeline with scaling and Ridge regression\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Set up the parameter grid for alpha (lambda)\n",
    "param_grid = {'ridge__alpha': lambdas}\n",
    "\n",
    "# Use GridSearchCV to perform cross-validation over the lambdas\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "# Get the cross-validated MSEs and standard deviations\n",
    "mean_test_scores = -grid_search.cv_results_['mean_test_score']\n",
    "std_test_scores = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "# Get the best alpha (lambda) value\n",
    "best_alpha = grid_search.best_estimator_.named_steps['ridge'].alpha\n",
    "\n",
    "# Plotting the cross-validated MSE vs. -log(lambda)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(-np.log(lambdas), mean_test_scores, yerr=std_test_scores / np.sqrt(5), fmt='o-')\n",
    "plt.axvline(-np.log(best_alpha), color='k', linestyle='--')\n",
    "plt.xlabel('$-\\\\log(\\\\lambda)$', fontsize=20)\n",
    "plt.ylabel('Cross-validated MSE', fontsize=20)\n",
    "plt.title('Ridge Regression Cross-Validated MSE', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get and print the best alpha (lambda) value\n",
    "best_alpha = grid_search.best_estimator_.named_steps['ridge'].alpha\n",
    "print(f\"Optimal alpha (lambda) value: {best_alpha}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28651077-6ae5-4a69-8da6-7b5045c2a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging; using all features\n",
    "\n",
    "regr_bagg = RandomForestClassifier(max_features= 18, random_state=1) \n",
    "regr_bagg.fit(X, y)\n",
    "\n",
    "\n",
    "pred = regr_bagg.predict(X)\n",
    "\n",
    "plt.scatter(pred, y, label='log price')\n",
    "plt.plot([0, 1], [0, 1], '--k', transform=plt.gca().transAxes)\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('y')\n",
    "\n",
    "\n",
    "bag_mse = mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044053a-3e64-453d-8163-42993a5a84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "import sklearn.model_selection as skm\n",
    "(X_train,\n",
    " X_test,\n",
    " y_train,\n",
    " y_test) = skm.train_test_split(X,\n",
    "                                y,\n",
    "                                test_size=0.3,\n",
    "                                random_state=0)\n",
    "boost_boston = GBC(n_estimators=5000,\n",
    "                   learning_rate=0.001,\n",
    "                   max_depth=3,\n",
    "                   random_state=0)\n",
    "boost_boston.fit(X_train, y_train)\n",
    "test_error = np.zeros_like(boost_boston.train_score_)\n",
    "for idx, y_ in enumerate(boost_boston.staged_predict(X_test)):\n",
    "   test_error[idx] = np.mean((y_test - y_)**2)\n",
    "\n",
    "plot_idx = np.arange(boost_boston.train_score_.shape[0])\n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,\n",
    "        boost_boston.train_score_,\n",
    "        'b',\n",
    "        label='Training')\n",
    "ax.plot(plot_idx,\n",
    "        test_error,\n",
    "        'r',\n",
    "        label='Test')\n",
    "ax.legend();\n",
    "y_hat_boost = boost_boston.predict(X_test);\n",
    "boost_mse = np.mean((y_test - y_hat_boost)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f753e-1afa-4fd3-8abd-f0d352cea644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "\n",
    "# Encode target labels if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Dictionary to store models and results\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(max_features=5, random_state=0),\n",
    "    'Bagging': BaggingClassifier(random_state=0),\n",
    "    'Boosting': GradientBoostingClassifier(n_estimators=5000, learning_rate=0.001, max_depth=3,random_state=0),\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "}\n",
    "\n",
    "# Loop through each model, fit, predict and calculate MSE and RMSE\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X, y_encoded)\n",
    "    \n",
    "    # Predict class probabilities\n",
    "    y_prob = model.predict_proba(X)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_encoded, y_pred)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame and display\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065bf74-0a52-47ee-94cc-9045a7cbf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import econml\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "estimate_dml = model.estimate_effect(\n",
    "    identified_estimand=estimand,\n",
    "    method_name='backdoor.econml.dml.DML',\n",
    "    method_params={\n",
    "        'init_params': {\n",
    "            'model_y': GradientBoostingRegressor(),\n",
    "            'model_t': GradientBoostingRegressor(),\n",
    "            'model_final': LassoCV(fit_intercept=False),\n",
    "        },\n",
    "        'fit_params': {}}\n",
    ")\n",
    "\n",
    "print(f'Estimate of causal effect (DML): {estimate_dml.value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb6bcc-9fb5-4bca-bd8b-cb451e6391b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_lr = model.estimate_effect(\n",
    "    identified_estimand=estimand,\n",
    "    method_name='backdoor.linear_regression')\n",
    "\n",
    "print(f'Estimate of causal effect (linear regression): {estimate_lr.value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf50dd4-d4f4-4a0b-bb07-bef7ad4cc25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cause = model.refute_estimate(\n",
    "    estimand=estimand, \n",
    "    estimate=estimate,\n",
    "    method_name='random_common_cause'\n",
    ")\n",
    "print(random_cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ee32d-261c-457c-b3a4-e91ba0b54c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "placebo_refuter = model.refute_estimate(\n",
    "    estimand=estimand, \n",
    "    estimate=estimate,\n",
    "    method_name='placebo_treatment_refuter'\n",
    ")\n",
    "print(placebo_refuter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e376ad27-8e6e-4bc6-875d-02f886852323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running model for Rating\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Rating:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: 0.0176**\n",
      "Standard Error: (0.0078)\n",
      "Age: -0.0000\n",
      "Standard Error: (0.0001)\n",
      "Price: -0.0257\n",
      "Standard Error: (0.0292)\n",
      "Log_Firm_Size: -0.0050\n",
      "Standard Error: (0.0072)\n",
      "One_Employee: -0.0365*\n",
      "Standard Error: (0.0214)\n",
      "Feature_Update: 0.0123**\n",
      "Standard Error: (0.0048)\n",
      "Log_Demand: -0.0769***\n",
      "Standard Error: (0.0078)\n",
      "\n",
      "Observations: 88,566\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0246\n",
      "\n",
      "============================================================\n",
      "Running model for Log_Demand\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Log_Demand:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: -0.0256\n",
      "Standard Error: (0.0178)\n",
      "Age: -0.0003*\n",
      "Standard Error: (0.0002)\n",
      "Price: -1.1874**\n",
      "Standard Error: (0.4895)\n",
      "Log_Firm_Size: 0.1755***\n",
      "Standard Error: (0.0220)\n",
      "One_Employee: 0.0047\n",
      "Standard Error: (0.0589)\n",
      "Feature_Update: -0.0786***\n",
      "Standard Error: (0.0249)\n",
      "\n",
      "Observations: 93,881\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0110\n",
      "\n",
      "============================================================\n",
      "Running model for File_Size\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azraj\\anaconda3\\Lib\\site-packages\\linearmodels\\panel\\model.py:1219: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(dependent, exog, weights=weights, check_rank=check_rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for File_Size:\n",
      "--------------------------------------------------\n",
      "TREATXAFTER: -0.0822\n",
      "Standard Error: (0.1780)\n",
      "Age: -0.0024\n",
      "Standard Error: (0.0016)\n",
      "Price: -5.5422\n",
      "Standard Error: (4.4768)\n",
      "Log_Firm_Size: -0.1575\n",
      "Standard Error: (0.2130)\n",
      "One_Employee: -1.0756\n",
      "Standard Error: (0.9424)\n",
      "Feature_Update: 1.2139***\n",
      "Standard Error: (0.3387)\n",
      "Log_Demand: 0.3238**\n",
      "Standard Error: (0.1362)\n",
      "\n",
      "Observations: 73,067\n",
      "Game fixed effects: x\n",
      "Month fixed effects: x\n",
      "R-squared: 0.0031\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_75980\\2846622990.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpanel_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpanel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_75980\\2846622990.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;34m'Standard_Error'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;34m'P_Value'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;34m'R_Squared'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             }\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regression_results.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from linearmodels import PanelOLS\n",
    "\n",
    "def prepare_data(panel_data):\n",
    "    \"\"\"Prepare data for regression analysis\"\"\"\n",
    "    df = panel_data.copy()\n",
    "    \n",
    "    # Convert to panel format\n",
    "    df = df.set_index(['app_num', 'ym'])\n",
    "    \n",
    "    # Ensure datatypes\n",
    "    numeric_cols = ['Feature_Update', 'TREATXAFTER', 'Log_Demand', 'Age', \n",
    "                    'Price', 'Log_Firm_Size', 'One_Employee', 'Feature_Update_lag',\n",
    "                    'Rating', 'File_Size']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    df['genre_num'] = df['genre_num'].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_model(data, dependent_var, controls=True):\n",
    "    \"\"\"Run the DiD model for the specified dependent variable\"\"\"\n",
    "    exog_vars = ['TREATXAFTER']\n",
    "    \n",
    "    # Add controls\n",
    "    if controls:\n",
    "        additional_vars = ['Age', 'Price', 'Log_Firm_Size', 'One_Employee', 'Feature_Update']\n",
    "        if dependent_var != 'Log_Demand':\n",
    "            additional_vars.append('Log_Demand')\n",
    "        exog_vars.extend(additional_vars)\n",
    "    \n",
    "    # Drop rows with NaN in the dependent variable\n",
    "    data = data.dropna(subset=[dependent_var])\n",
    "    \n",
    "    # Create the model\n",
    "    model = PanelOLS(\n",
    "        dependent=data[dependent_var],\n",
    "        exog=data[exog_vars],\n",
    "        entity_effects=True,\n",
    "        time_effects=True,\n",
    "        check_rank=False\n",
    "    )\n",
    "    \n",
    "    # Fit with clustered standard errors\n",
    "    results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_formatted_results(results, dependent_var):\n",
    "    \"\"\"Print formatted results\"\"\"\n",
    "    print(f\"\\nResults for {dependent_var}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Print coefficients and standard errors for all variables\n",
    "    for var in results.params.index:\n",
    "        coef = results.params[var]\n",
    "        se = results.std_errors[var]\n",
    "        stars = ''\n",
    "        pval = results.pvalues[var]\n",
    "        if pval < 0.01:\n",
    "            stars = '***'\n",
    "        elif pval < 0.05:\n",
    "            stars = '**'\n",
    "        elif pval < 0.1:\n",
    "            stars = '*'\n",
    "        print(f\"{var}: {coef:.4f}{stars}\")\n",
    "        print(f\"Standard Error: ({se:.4f})\")\n",
    "    \n",
    "    print(f\"\\nObservations: {results.nobs:,}\")\n",
    "    print(f\"Game fixed effects: x\")\n",
    "    print(f\"Month fixed effects: x\")\n",
    "    print(f\"R-squared: {results.rsquared:.4f}\")\n",
    "\n",
    "def run_new_models(data):\n",
    "    \"\"\"Run models for Rating, Log_Demand, and File_Size\"\"\"\n",
    "    dependent_vars = ['Rating', 'Log_Demand', 'File_Size']\n",
    "    results = {}\n",
    "    \n",
    "    for dv in dependent_vars:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running model for {dv}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model_results = run_model(data, dv)\n",
    "        print_formatted_results(model_results, dv)\n",
    "        results[dv] = model_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Load the data\n",
    "    filepath = r'C:\\Users\\azraj\\OneDrive\\Desktop\\MA Economics\\Fall Term\\Causal ML\\Project\\Targetted Ads\\replication_package_MS-INS-21-00828\\at.dta'\n",
    "    panel_data = pd.read_stata(filepath)\n",
    "    \n",
    "    # Prepare the data\n",
    "    panel_data = prepare_data(panel_data)\n",
    "    \n",
    "    # Run new models\n",
    "    new_results = run_new_models(panel_data)\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    results_df = pd.DataFrame()\n",
    "    for dv, model_results in new_results.items():\n",
    "        for var in model_results.params.index:\n",
    "            row = {\n",
    "                'Dependent_Variable': dv,\n",
    "                'Independent_Variable': var,\n",
    "                'Coefficient': model_results.params[var],\n",
    "                'Standard_Error': model_results.std_errors[var],\n",
    "                'P_Value': model_results.pvalues[var],\n",
    "                'R_Squared': model_results.rsquared\n",
    "            }\n",
    "            results_df = results_df.append(row, ignore_index=True)\n",
    "    \n",
    "    results_df.to_csv('regression_results.csv', index=False)\n",
    "    \n",
    "    return new_results, panel_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, panel_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "141fcc65-6c72-4006-89c8-8554b1ed9244",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot setitem on a Categorical with a new category (missing), set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 137\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[121], line 132\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m panel_data \u001b[38;5;241m=\u001b[39m prepare_data(panel_data)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Run regularized models\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m results \u001b[38;5;241m=\u001b[39m run_regularized_models(panel_data)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[1;32mIn[121], line 50\u001b[0m, in \u001b[0;36mrun_regularized_models\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     47\u001b[0m X_numeric \u001b[38;5;241m=\u001b[39m data[numeric_vars]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Fill missing values in categorical variables\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m X_categorical \u001b[38;5;241m=\u001b[39m data[categorical_vars]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Encode categorical variables using one-hot encoding\u001b[39;00m\n\u001b[0;32m     53\u001b[0m X_categorical_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(X_categorical, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:7297\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   7295\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   7296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7297\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mfillna(\n\u001b[0;32m   7298\u001b[0m             value\u001b[38;5;241m=\u001b[39mvalue, limit\u001b[38;5;241m=\u001b[39mlimit, inplace\u001b[38;5;241m=\u001b[39minplace, downcast\u001b[38;5;241m=\u001b[39mdowncast\n\u001b[0;32m   7299\u001b[0m         )\n\u001b[0;32m   7300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   7301\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotna(), value)\u001b[38;5;241m.\u001b[39m_mgr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:173\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_with_block(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfillna\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m     value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m    176\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    177\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m    178\u001b[0m     downcast\u001b[38;5;241m=\u001b[39mdowncast,\n\u001b[0;32m    179\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    180\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2008\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[1;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2006\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[0;32m   2007\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2008\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mfillna(value\u001b[38;5;241m=\u001b[39mvalue, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[0;32m   2011\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2012\u001b[0m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[0;32m   2013\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray.fillna added a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2020\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:363\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[1;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_setitem_value(value)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[0;32m    366\u001b[0m         new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1562\u001b[0m, in \u001b[0;36mCategorical._validate_setitem_value\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_listlike(value)\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_scalar(value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1587\u001b[0m, in \u001b[0;36mCategorical._validate_scalar\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   1585\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbox_scalar(fill_value)\n\u001b[0;32m   1586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot setitem on a Categorical with a new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1589\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfill_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), set the categories first\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1590\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fill_value\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot setitem on a Categorical with a new category (missing), set the categories first"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, lasso_path, enet_path, Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(panel_data):\n",
    "    \"\"\"Prepare data for regression analysis\"\"\"\n",
    "    df = panel_data.copy()\n",
    "    \n",
    "    # Convert to panel format\n",
    "    df = df.set_index(['app_num', 'ym'])\n",
    "    \n",
    "    # Ensure datatypes\n",
    "    numeric_cols = [\n",
    "        'Feature_Update', 'Log_Demand', 'Age', 'Price', 'Log_Firm_Size',\n",
    "        'One_Employee', 'Feature_Update_lag', 'Rating', 'File_Size'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    df['genre_num'] = df['genre_num'].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_regularized_models(data):\n",
    "    \"\"\"Run LASSO, Ridge, and Elastic Net models\"\"\"\n",
    "    indep_vars = [\n",
    "        'Ad_Networks', 'Ad_Views', 'Age', 'Bug_Fix', 'Charges_Price',\n",
    "        'Collects_User_ID', 'Feature_Update', 'File_Size', 'Firm_Size', 'Log_Demand',\n",
    "        'Log_Firm_Size', 'Log_Price', 'One_Employee', 'Permissions',\n",
    "        'Price', 'Top_Demanded', 'Top_Rated', 'Undiversified',\n",
    "        'Update', 'Young', 'ad_networks_above_median', 'ads_above_median',\n",
    "        'ann_TREAT', 'app_num', 'collected_id', 'genre_cons', 'genre_num'\n",
    "    ]\n",
    "\n",
    "    # Ensure all independent variables are present in the data\n",
    "    indep_vars = [var for var in indep_vars if var in data.columns]\n",
    "\n",
    "    # Separate numeric and categorical variables\n",
    "    numeric_vars = data[indep_vars].select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_vars = data[indep_vars].select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "    # Fill missing values in numeric variables\n",
    "    X_numeric = data[numeric_vars].fillna(0)\n",
    "\n",
    "    # Fill missing values in categorical variables\n",
    "    X_categorical = data[categorical_vars].fillna('missing')\n",
    "\n",
    "    # Encode categorical variables using one-hot encoding\n",
    "    X_categorical_encoded = pd.get_dummies(X_categorical, drop_first=True)\n",
    "\n",
    "    # Combine numeric and encoded categorical variables\n",
    "    X = pd.concat([X_numeric, X_categorical_encoded], axis=1)\n",
    "\n",
    "    # Prepare the target variable\n",
    "    Y = data['Rating'].fillna(data['Rating'].mean())\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Define cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # LASSO Regression\n",
    "    lasso_cv = LassoCV(cv=kfold, random_state=42, max_iter=10000)\n",
    "    lasso_cv.fit(X_scaled, Y)\n",
    "    best_alpha_lasso = lasso_cv.alpha_\n",
    "    print(f\"\\nOptimal alpha for LASSO: {best_alpha_lasso}\")\n",
    "    \n",
    "    # Compute LASSO path\n",
    "    alphas_lasso, coefs_lasso, _ = lasso_path(X_scaled, Y, alphas=None)\n",
    "    plot_coefficient_convergence(alphas_lasso, coefs_lasso, X.columns, \"LASSO Regression Coefficients\")\n",
    "    \n",
    "    # Ridge Regression\n",
    "    ridge_cv = RidgeCV(cv=kfold, alphas=np.logspace(-5, 5, 100))\n",
    "    ridge_cv.fit(X_scaled, Y)\n",
    "    best_alpha_ridge = ridge_cv.alpha_\n",
    "    print(f\"\\nOptimal alpha for Ridge: {best_alpha_ridge}\")\n",
    "    \n",
    "    # Compute Ridge path\n",
    "    alphas_ridge = np.logspace(-5, 5, 100)\n",
    "    coefs_ridge = []\n",
    "    for alpha in alphas_ridge:\n",
    "        ridge = Ridge(alpha=alpha, fit_intercept=True)\n",
    "        ridge.fit(X_scaled, Y)\n",
    "        coefs_ridge.append(ridge.coef_)\n",
    "    coefs_ridge = np.array(coefs_ridge).T\n",
    "    plot_coefficient_convergence(alphas_ridge, coefs_ridge, X.columns, \"Ridge Regression Coefficients\")\n",
    "    \n",
    "    # Elastic Net Regression\n",
    "    elastic_net_cv = ElasticNetCV(cv=kfold, random_state=42, max_iter=10000, l1_ratio=[.1, .5, .7, .9, .95, .99, 1])\n",
    "    elastic_net_cv.fit(X_scaled, Y)\n",
    "    best_alpha_enet = elastic_net_cv.alpha_\n",
    "    best_l1_ratio_enet = elastic_net_cv.l1_ratio_\n",
    "    print(f\"\\nOptimal alpha for Elastic Net: {best_alpha_enet}\")\n",
    "    print(f\"Optimal l1_ratio for Elastic Net: {best_l1_ratio_enet}\")\n",
    "    \n",
    "    # Compute Elastic Net path\n",
    "    alphas_enet, coefs_enet, _ = enet_path(X_scaled, Y, l1_ratio=best_l1_ratio_enet, fit_intercept=True)\n",
    "    plot_coefficient_convergence(alphas_enet, coefs_enet, X.columns, \"Elastic Net Regression Coefficients\")\n",
    "    \n",
    "    return {\n",
    "        'LASSO': lasso_cv,\n",
    "        'Ridge': ridge_cv,\n",
    "        'Elastic Net': elastic_net_cv\n",
    "    }\n",
    "\n",
    "def plot_coefficient_convergence(alphas, coefs, feature_names, title):\n",
    "    \"\"\"Plot the convergence of coefficients for each model\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for coef, name in zip(coefs, feature_names):\n",
    "        plt.plot(np.log10(alphas), coef, label=name)\n",
    "    plt.xlabel('$\\log_{10}(\\lambda)$', fontsize=14)\n",
    "    plt.ylabel('Coefficients', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend(loc='best', ncol=2)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Load and prepare the data\n",
    "    filepath = r'C:\\Users\\azraj\\OneDrive\\Desktop\\MA Economics\\Fall Term\\Causal ML\\Project\\Targetted Ads\\replication_package_MS-INS-21-00828\\at.dta'\n",
    "    panel_data = pd.read_stata(filepath)\n",
    "    panel_data = prepare_data(panel_data)\n",
    "    \n",
    "    # Run regularized models\n",
    "    results = run_regularized_models(panel_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24be2970-2143-4c19-9f27-acbd55b92ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\azraj\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\azraj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\azraj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\azraj\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\azraj\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
